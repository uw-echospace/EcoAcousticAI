name: Process OSN Bucket Data with Docker Model

on:
  schedule:
    - cron: '0 0 * * *'  # Every night at midnight UTC
  workflow_dispatch:  # Allow manual triggering

jobs:
  process_data:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Checkout repository (if any code changes are needed)
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Build docker images
        run: docker build -t buzzfindr-image -f ./buzzfindr/Dockerfile .

      # Step 2: Install rclone and configure it for OSN access
      - name: Set up rclone for OSN access
        run: |
          sudo apt-get update
          sudo apt-get install -y rclone
          mkdir -p ~/.config/rclone
          echo "[osn_sdsc_ubna]" > ~/.config/rclone/rclone.conf
          echo "type = s3" >> ~/.config/rclone/rclone.conf
          echo "provider = Ceph" >> ~/.config/rclone/rclone.conf
          echo "access_key_id = " >> ~/.config/rclone/rclone.conf  # Leave blank for public access
          echo "secret_access_key = " >> ~/.config/rclone/rclone.conf  # Leave blank for public access
          echo "endpoint = https://sdsc.osn.xsede.org" >> ~/.config/rclone/rclone.conf
          echo "no_check_bucket = true" >> ~/.config/rclone/rclone.conf

      # Step 3: Download the latest directory info artifact (if exists)
      - name: Download latest directory info artifact (if exists)
        uses: actions/download-artifact@v4
        with:
          name: latest-directory-artifact
          path: ./latest_directory.txt
        continue-on-error: true  # If the artifact doesn't exist, continue without error

      # Step 4: Check for the most recent directory in the OSN bucket
      - name: Check for most recent directory in OSN bucket
        id: check_data
        run: |
          # List directories in the OSN bucket using rclone
          NEW_DATA=$(rclone lsd osn_sdsc_ubna:bio230143-bucket01 | sort | tail -n 1| awk '{print $NF}')
          echo "Most recent directory: $NEW_DATA"

          # Default latest directory (if no previous directory file exists)
          LAST_PROCESSED_DIRECTORY="ubna_data_04"

          # If previous directory exists in latest_directory.txt, use it
          if [[ -f latest_directory.txt ]]; then
            LAST_PROCESSED_DIRECTORY=$(cat latest_directory.txt)
          fi

          # Compare the most recent directory to the last processed directory
          if [[ "$NEW_DATA" == "$LAST_PROCESSED_DIRECTORY" ]]; then
            echo "No new data found"
            echo "::set-output name=new_data::false"
          else
            echo "New data detected"
            echo "::set-output name=new_data::true"
            echo "::set-output name=new_data_path::osn_sdsc_ubna:bio230143-bucket01/${NEW_DATA}"

            # Update the latest processed directory
            echo "$NEW_DATA" > latest_directory.txt
          fi

      # Step 5: Mount the OSN bucket and process data in Docker
      - name: Mount OSN bucket and process data in Docker
        if: steps.check_data.outputs.new_data == 'true'
        run: |
            mkdir -p /tmp/osn_bucket/

            NEW_DATA=$(rclone lsd osn_sdsc_ubna:bio230143-bucket01 | sort | tail -n 1| awk '{print $NF}')

            # Step 2: Mount the OSN bucket using rclone (with daemon option)
            rclone mount "osn_sdsc_ubna:bio230143-bucket01$NEW_DATA/" /tmp/osn_bucket/ --daemon

            # Step 3: Add a short delay to ensure the mount has completed (optional)
            sleep 200  # Adjust sleep time as necessary to give rclone time to mount

            # Step 4: Get the most recent directory or file to process (assuming NEW_DATA is set elsewhere)
            #NEW_DATA_PATH="/tmp/osn_bucket/$NEW_DATA/"
            CONTENTS = $(ls /tmp/osn_bucket/)
            echo $CONTENTS
            # Step 5: Print the NEW_DATA_PATH to check if it's correct
            #echo "Checking path: $NEW_DATA_PATH/"
            
            # Step 6: Ensure the file exists and is accessible
            #if [[ ! -d "$NEW_DATA_PATH" ]]; then  # Use -d to check for directories
                #echo "Error: Data directory not found: $NEW_DATA_PATH"
                #exit 1
            #fi
            
            # Step 7: Run the Docker container with the mounted OSN bucket file
            docker run -v /tmp/osn_bucket/:/app/recordings_2023/ buzzfindr-image:latest
            
            # Clean up (optional, unmount the rclone mount)
            umount /tmp/osn_bucket/

      # Step 6: Upload the latest directory info as an artifact for next run
      - name: Upload latest directory info artifact
        uses: actions/upload-artifact@v4
        with:
          name: latest-directory-artifact
          path: latest_directory.txt
          
      # Step 7: Move the output to Manila folder on Jetstream2
      - name: Move output to Manila folder on Jetstream2
        if: steps.check_data.outputs.new_data == 'true'
        run: |
          sshpass -p "${{ secrets.JETSTREAM_PASSWORD }}" scp -r ~/osn_bucket/output/ user@jetstream2:/path/to/manila/folder/
          echo "Output moved to Jetstream2 manila folder"
